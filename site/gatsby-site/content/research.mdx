---
title: "Researcher Guide"
metaTitle: "Research incidents and/or Contribute to the Database"
metaDescription: "The database is in the process of opening to the world for research purposes"
---

# Defining an "AI Incident"

The commercial air travel industry owes much of its increasing safety to systematically analyzing and archiving past accidents and incidents within a shared database. In aviation, an accident is a case where substantial damage or loss of life occurs. Incidents are cases where the risk of an accident substantially increases. For example, when a small fire is quickly extinguished in a cockpit it is an "incident" but if the fire burns crew members in the course of being extinguished it is an "accident." The FAA [aviation database](https://www.faa.gov/data_research/accident_incident/) indexes flight log data and subsequent expert investigations into comprehensive examinations of both technological and human factors. In part due to this continual self-examination, air travel is one of the safest forms of travel. Decades of iterative improvements to safety systems and training have decreased fatalities [81 fold](https://theblogbyjavier.com/2020/01/02/aviation-safety-evolution-2019-update/) since 1970 when normalized for passenger miles.

Where the aviation industry has clear definitions, computer scientists and philosophers have long debated foundational definitions of artificial intelligence. In the absence of clear lines differentiating algorithms, intelligence, and the harms they may directly or indirectly cause, this database adopts an adaptive criteria for ingesting "incidents" where reports are accepted or rejected on the basis of a growing rule set.

More details about the acceptance criteria are available on the [criteria page](/research/1-criteria).

# Download the Index

The complete state of the database can be downloaded in weekly JSON, MongoDB, and CSV format [snapshots](/research/snapshots). We maintain these snapshots so you can create stable datasets for natural language processing research and academic analysis. Please [contact](/contact) to let us know what you are using the database for so we can list your work in the incident database and esnure your use case is not dropped from support.

# Citing the Database as a Whole

We invite you to cite:  
> McGregor, S. (2021) Preventing Repeated Real World AI Failures by Cataloging Incidents: The AI Incident Database. In Proceedings of the Thirty-Third Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-21). Virtual Conference.

The [pre-print](https://arxiv.org/abs/2011.08512) is available on arXiv.

# Citing a Specific Incident

Every incident has its own suggested citation that credits both the submitter(s) of the incident and the editor(s) of the incident. The submitters are the people that submitted reports associated with the incident and their names are listed in the order in which their submissions were added to the AIID. Since reports can be added to an incident record through time, our suggested citation format includes the access date. You can find incident citations at `https://incidentdatabase.ai/cite/INSERT_NUMBER_HERE`.

# Related Work

While formal AI incident research is relatively new, a number of people have been collecting what could be considered incidents. These include,

* [Awesome Machine Learning Interpretability: AI Incident Tracker](https://github.com/jphall663/awesome-machine-learning-interpretability/blob/master/README.md#ai-incident-tracker)
* [AI and Algorithimic Incidents and Controversies of Charlie Pownall](https://charliepownall.com/ai-algorithimic-incident-controversy-database/)
* [Map of Helpful and Harmful AI](https://map.ai-global.org/)

If you have an incident resource that could be added here, please [contact](/contact) us or open a pull request with the resource.
